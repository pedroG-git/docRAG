{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db2f9e69-3a07-4ebd-9894-2971f132e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f1cdf4a-39e6-4ea6-81b8-f591b7d9403f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Path to the main directory\n",
    "main_dir = 'data'\n",
    "documents = []\n",
    "\n",
    "# Traverse through the directory\n",
    "for root, dirs, files in os.walk(main_dir):\n",
    "    for file in files:\n",
    "        if file.endswith('.md'):  # Check for text files\n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:  # Use utf-8 encoding\n",
    "                documents.append(f.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d56b7237-9235-49cf-9ba0-0ea9f09eb1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=500):\n",
    "    return [text[i:i+chunk_size] for i in range(0, len(text), chunk_size)]\n",
    "\n",
    "chunks = [chunk_text(doc) for doc in documents]\n",
    "chunks = [chunk for sublist in chunks for chunk in sublist]  # Flatten the list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78730c21-aece-4c6b-86a1-e18b5e96520b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(chunks).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "314cccae-331b-4b9f-a274-06c3be422492",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Assuming 'chunks' contains your text chunks\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectors = vectorizer.fit_transform(chunks).toarray()\n",
    "\n",
    "import faiss\n",
    "\n",
    "# Get the dimensionality of the vectors\n",
    "dimension = vectors.shape[1]\n",
    "\n",
    "# Initialize the FAISS index for L2 distance\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "\n",
    "# Add the vectors to the index\n",
    "index.add(vectors.astype('float32'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c2f75b0-fd3e-4b5f-8022-ea4f9cacb4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_chunks(query, k=3):\n",
    "    query_vector = vectorizer.transform([query]).toarray().astype('float32')\n",
    "    distances, indices = index.search(query_vector, k)\n",
    "    return [chunks[i] for i in indices[0]]\n",
    "\n",
    "query = \"Your question here\"\n",
    "relevant_chunks = retrieve_chunks(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4fa9000-381a-4d6a-909d-fd9a596ad935",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \" \".join(relevant_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4333c01-7905-4722-a0fc-e7b6f0fd2676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'ChatCompletion' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m\n\u001b[1;32m      6\u001b[0m client \u001b[38;5;241m=\u001b[39m OpenAI(\n\u001b[1;32m      7\u001b[0m     api_key\u001b[38;5;241m=\u001b[39mapi_key\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     11\u001b[0m     model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     messages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     13\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     14\u001b[0m     ]\n\u001b[1;32m     15\u001b[0m )\n\u001b[0;32m---> 17\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mresponse\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mchoices\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(answer)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'ChatCompletion' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "print(api_key)\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=api_key\n",
    ")\n",
    "\n",
    "# Prepare your context and query\n",
    "context = \"Your context here\"\n",
    "query = \"Your question here\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": f\"{context}\\n\\n{query}\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "answer = response['choices'][0]['message']['content']\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f7bc1a6-edce-4bb1-81d1-7d1e5a294a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(os.environ.get(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b043f-e14e-479d-8890-723c597e6a9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
